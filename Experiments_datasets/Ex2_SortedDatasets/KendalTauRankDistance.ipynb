{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kendal Tau Rank Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will calculate the Kendal Tau Rank Distance for 2 cases:\n",
    "- The distance between the Lexical Similarity and Eigenvalue Laplacia for model GPT-3.5\n",
    "- The distance between the Lexical Similarity and Eigenvalue Laplacia for model GPT-4\n",
    "\n",
    "in this way, we will find out which methods are closer in case of ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: since the datasets with Lexical Similarity are significant longer with 129 rows of uncertaity scores and datasets with Eigenvalue Laplacian with 19 rows of uncertainty scores, we will calculate the distance within the common questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by calculating the distance between the Lexical Similarity and Eigenvalue Laplacia for model GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall tau rank distance: 0.9558823529411765\n",
      "P-value: 0.7654110627827273\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import kendalltau\n",
    "\n",
    "# Step 1: Read lists from Excel\n",
    "excel_file_LS_3 = 'results_LS_3 - Sorted.xlsx'\n",
    "excel_file_EVL_3 = 'results_EVL_3 - Sorted.xlsx'\n",
    "df_LS_3 = pd.read_excel(excel_file_LS_3)\n",
    "df_EVL_3 = pd.read_excel(excel_file_EVL_3)\n",
    "\n",
    "# Step 2: Identify common 'Input Prompt' elements\n",
    "common_prompts = df_EVL_3['Input Prompt'].dropna().tolist()\n",
    "\n",
    "# Step 3: Filter and order the longer DataFrame (df_LS_3) to match the shorter list (df_EVL_3)\n",
    "filtered_df_LS_3 = df_LS_3[df_LS_3['Input Prompt'].isin(common_prompts)]\n",
    "ordered_filtered_df_LS_3 = filtered_df_LS_3.set_index('Input Prompt').loc[common_prompts].reset_index()\n",
    "\n",
    "# Step 4: Ensure the order of the shorter DataFrame (df_EVL_3) follows the common prompts\n",
    "ordered_df_EVL_3 = df_EVL_3.set_index('Input Prompt').loc[common_prompts].reset_index()\n",
    "\n",
    "# Step 5: Extract the 'Uncertainty' values from both ordered DataFrames\n",
    "uncertain_LS_3 = ordered_filtered_df_LS_3['Uncertainty'].tolist()\n",
    "uncertain_EVL_3 = ordered_df_EVL_3['Uncertainty'].tolist()\n",
    "\n",
    "# Step 6: Calculate Kendall tau rank distance\n",
    "tau, p_value = kendalltau(uncertain_LS_3, uncertain_EVL_3)\n",
    "\n",
    "# Output the result\n",
    "print(f\"Kendall tau rank distance: {1 - tau}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the distance between the Lexical Similarity and Eigenvalue Laplacia for model GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall tau rank distance: 1.0073529411764706\n",
      "P-value: 0.9603371858957213\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import kendalltau\n",
    "\n",
    "# Step 1: Read lists from Excel\n",
    "excel_file_LS_4 = 'results_LS_4 - Sorted.xlsx'\n",
    "excel_file_EVL_4 = 'results_EVL_4 - Sorted.xlsx'\n",
    "df_LS_4 = pd.read_excel(excel_file_LS_4)\n",
    "df_EVL_4 = pd.read_excel(excel_file_EVL_4)\n",
    "\n",
    "# Step 2: Identify common 'Input Prompt' elements\n",
    "common_prompts = df_EVL_4['Input Prompt'].dropna().tolist()\n",
    "\n",
    "# Step 3: Filter and order the longer DataFrame (df_LS_4) to match the shorter list (df_EVL_4)\n",
    "filtered_df_LS_4 = df_LS_4[df_LS_4['Input Prompt'].isin(common_prompts)]\n",
    "ordered_filtered_df_LS_4 = filtered_df_LS_4.set_index('Input Prompt').loc[common_prompts].reset_index()\n",
    "\n",
    "# Step 4: Ensure the order of the shorter DataFrame (df_EVL_4) follows the common prompts\n",
    "ordered_df_EVL_4 = df_EVL_4.set_index('Input Prompt').loc[common_prompts].reset_index()\n",
    "\n",
    "# Step 5: Extract the 'Uncertainty' values from both ordered DataFrames\n",
    "uncertain_LS_4 = ordered_filtered_df_LS_4['Uncertainty'].tolist()\n",
    "uncertain_EVL_4 = ordered_df_EVL_4['Uncertainty'].tolist()\n",
    "\n",
    "# Step 6: Calculate Kendall tau rank distance\n",
    "tau, p_value = kendalltau(uncertain_LS_4, uncertain_EVL_4)\n",
    "\n",
    "# Output the result\n",
    "print(f\"Kendall tau rank distance: {1 - tau}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
